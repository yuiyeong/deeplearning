{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MNIST 실습 with MPS\n",
    "- MNIST dataset: 28x28 크기의 흑백 손글씨 이미지로, 0 ~ 9가 적혀있는 데이터셋\n",
    "- MNIST는 손글씨 사진과 어떤 숫자를 의미하는지에 대한 label의 pair들로 구성\n",
    "- 학습과 평가를 MPS(Metal Performance Shaders) 를 이용해서 진행\n",
    "- [학습 및 평가 결과 보고서](https://github.com/yuiyeong/deeplearning/blob/main/docs/report_presentation01_practice.md)"
   ],
   "id": "e4cfff6f7b699b35"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T05:16:39.699013Z",
     "start_time": "2024-09-11T05:16:38.695081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import SGD"
   ],
   "id": "cb35c18ef0a93e04",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T11:10:12.424437Z",
     "start_time": "2024-09-11T11:10:12.420140Z"
    }
   },
   "cell_type": "code",
   "source": "ROOT_DIR = \"../data\"",
   "id": "3ddf30ca0d6c443b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T05:16:41.492861Z",
     "start_time": "2024-09-11T05:16:41.488414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleMPSModel(nn.Module):\n",
    "    def __init__(self, input_dim, n_dim):\n",
    "        super(SimpleMPSModel, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(input_dim, n_dim)\n",
    "        self.layer2 = nn.Linear(n_dim, n_dim)\n",
    "        self.layer3 = nn.Linear(n_dim, 1)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.activation(self.layer1(x))\n",
    "        x = self.activation(self.layer2(x))\n",
    "        x = self.activation(self.layer3(x))\n",
    "        return x"
   ],
   "id": "70e36afa727c6c13",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T05:16:42.550533Z",
     "start_time": "2024-09-11T05:16:42.547601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ],
   "id": "fc8e9213d68edcc6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T05:16:43.364154Z",
     "start_time": "2024-09-11T05:16:43.359537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(device, n_epochs, lr, batch_size, num_workers, pin_memory):\n",
    "    train_set = torchvision.datasets.MNIST(\n",
    "        root=ROOT_DIR, train=True, download=True, transform=transforms.ToTensor()\n",
    "    )\n",
    "    train_set_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    model = SimpleMPSModel(1 * 28 * 28, 1024).to(device)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.0\n",
    "        for data in train_set_loader:\n",
    "            model.zero_grad()\n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            preds = model(inputs)\n",
    "\n",
    "            loss = (preds[:, 0] - labels).pow(2).mean()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(\"  \", f\"Epoch {epoch + 1:3d} | Sum of Loss: {total_loss}\")\n",
    "    return model"
   ],
   "id": "d2535b6d00392e64",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T05:16:44.506822Z",
     "start_time": "2024-09-11T05:16:44.502205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(device, model, batch_size):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "\n",
    "    test_set = torchvision.datasets.MNIST(\n",
    "        root=ROOT_DIR, train=False, download=True, transform=transforms.ToTensor()\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_set, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = (outputs[:, 0] - labels).pow(2).mean()\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "\n",
    "    return avg_loss"
   ],
   "id": "3dc71f62713247c5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T05:16:45.945624Z",
     "start_time": "2024-09-11T05:16:45.942205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test(num, device, n_epochs, lr, batch_size, num_workers=4, pin_memory=True):\n",
    "    print(\"<\" * 20, f\"{num} 번째 테스트\", \">\" * 20)\n",
    "    print(\"device:\", device)\n",
    "    print(\"batch_size:\", batch_size)\n",
    "    print(\"n_epochs:\", n_epochs)\n",
    "    print(\"lr:\", lr)\n",
    "    print(\"num_workers:\", num_workers)\n",
    "    print(\"pin_memory:\", pin_memory)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    trained_model = train(\n",
    "        device=device,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "    print(\"Finish Training.\")\n",
    "\n",
    "    mean_loss = evaluate_model(\n",
    "        device=device, model=trained_model, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    print(\"Average Loss:\", mean_loss)\n",
    "    print(\"=\" * 120)"
   ],
   "id": "84f385f365f5e7c9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T05:16:47.334645Z",
     "start_time": "2024-09-11T05:16:47.318337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = get_device()\n",
    "device"
   ],
   "id": "71d9eb88127aae04",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T05:21:34.599829Z",
     "start_time": "2024-09-11T05:16:49.186041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test(\n",
    "    num=1,\n",
    "    device=device,\n",
    "    n_epochs=100,\n",
    "    lr=0.001,\n",
    "    batch_size=64,\n",
    ")"
   ],
   "id": "4fb30988e61a06f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<< 1 번째 테스트 >>>>>>>>>>>>>>>>>>>>\n",
      "device: mps\n",
      "batch_size: 64\n",
      "n_epochs: 100\n",
      "lr: 0.001\n",
      "num_workers: 4\n",
      "pin_memory: True\n",
      "--------------------------------------------------------------------------------\n",
      "   Epoch   1 | Sum of Loss: 4656.526816248894\n",
      "   Epoch   2 | Sum of Loss: 2520.8836246728897\n",
      "   Epoch   3 | Sum of Loss: 1846.4811725616455\n",
      "   Epoch   4 | Sum of Loss: 1462.0174854397774\n",
      "   Epoch   5 | Sum of Loss: 1225.9045073390007\n",
      "   Epoch   6 | Sum of Loss: 1075.2036587297916\n",
      "   Epoch   7 | Sum of Loss: 972.8748465180397\n",
      "   Epoch   8 | Sum of Loss: 895.1848843991756\n",
      "   Epoch   9 | Sum of Loss: 836.3045299947262\n",
      "   Epoch  10 | Sum of Loss: 783.4455498158932\n",
      "   Epoch  11 | Sum of Loss: 741.9677709192038\n",
      "   Epoch  12 | Sum of Loss: 706.2197566330433\n",
      "   Epoch  13 | Sum of Loss: 671.0826960802078\n",
      "   Epoch  14 | Sum of Loss: 641.7007465213537\n",
      "   Epoch  15 | Sum of Loss: 616.4688709527254\n",
      "   Epoch  16 | Sum of Loss: 591.2432393729687\n",
      "   Epoch  17 | Sum of Loss: 567.918739438057\n",
      "   Epoch  18 | Sum of Loss: 545.6406467556953\n",
      "   Epoch  19 | Sum of Loss: 527.5637939274311\n",
      "   Epoch  20 | Sum of Loss: 508.45717965066433\n",
      "   Epoch  21 | Sum of Loss: 492.19362984597683\n",
      "   Epoch  22 | Sum of Loss: 478.81734393537045\n",
      "   Epoch  23 | Sum of Loss: 465.15915471315384\n",
      "   Epoch  24 | Sum of Loss: 448.6817516684532\n",
      "   Epoch  25 | Sum of Loss: 435.2491885498166\n",
      "   Epoch  26 | Sum of Loss: 420.77051462233067\n",
      "   Epoch  27 | Sum of Loss: 411.6554233431816\n",
      "   Epoch  28 | Sum of Loss: 400.9044395759702\n",
      "   Epoch  29 | Sum of Loss: 388.3403391763568\n",
      "   Epoch  30 | Sum of Loss: 382.3674803227186\n",
      "   Epoch  31 | Sum of Loss: 372.83493345975876\n",
      "   Epoch  32 | Sum of Loss: 364.51807226985693\n",
      "   Epoch  33 | Sum of Loss: 353.1450970247388\n",
      "   Epoch  34 | Sum of Loss: 342.1175556778908\n",
      "   Epoch  35 | Sum of Loss: 335.15063091367483\n",
      "   Epoch  36 | Sum of Loss: 326.13698986917734\n",
      "   Epoch  37 | Sum of Loss: 319.3961921930313\n",
      "   Epoch  38 | Sum of Loss: 311.68706319481134\n",
      "   Epoch  39 | Sum of Loss: 308.2485447973013\n",
      "   Epoch  40 | Sum of Loss: 304.09061037003994\n",
      "   Epoch  41 | Sum of Loss: 290.3189794495702\n",
      "   Epoch  42 | Sum of Loss: 288.6995025202632\n",
      "   Epoch  43 | Sum of Loss: 279.26377435028553\n",
      "   Epoch  44 | Sum of Loss: 279.54560509324074\n",
      "   Epoch  45 | Sum of Loss: 270.3750548288226\n",
      "   Epoch  46 | Sum of Loss: 263.83078399300575\n",
      "   Epoch  47 | Sum of Loss: 260.30410338938236\n",
      "   Epoch  48 | Sum of Loss: 254.0110544487834\n",
      "   Epoch  49 | Sum of Loss: 241.03465289622545\n",
      "   Epoch  50 | Sum of Loss: 242.30737737566233\n",
      "   Epoch  51 | Sum of Loss: 241.3679077848792\n",
      "   Epoch  52 | Sum of Loss: 236.40538154542446\n",
      "   Epoch  53 | Sum of Loss: 239.06591818481684\n",
      "   Epoch  54 | Sum of Loss: 224.11095493286848\n",
      "   Epoch  55 | Sum of Loss: 223.26835026219487\n",
      "   Epoch  56 | Sum of Loss: 218.86040511354804\n",
      "   Epoch  57 | Sum of Loss: 211.77475444227457\n",
      "   Epoch  58 | Sum of Loss: 214.89802460372448\n",
      "   Epoch  59 | Sum of Loss: 206.2634888663888\n",
      "   Epoch  60 | Sum of Loss: 202.87745128571987\n",
      "   Epoch  61 | Sum of Loss: 204.40102564543486\n",
      "   Epoch  62 | Sum of Loss: 192.6502140685916\n",
      "   Epoch  63 | Sum of Loss: 193.0668416917324\n",
      "   Epoch  64 | Sum of Loss: 197.1485172212124\n",
      "   Epoch  65 | Sum of Loss: 183.87283043935895\n",
      "   Epoch  66 | Sum of Loss: 180.3052096441388\n",
      "   Epoch  67 | Sum of Loss: 177.19861471652985\n",
      "   Epoch  68 | Sum of Loss: 176.5592759028077\n",
      "   Epoch  69 | Sum of Loss: 175.64677024260163\n",
      "   Epoch  70 | Sum of Loss: 170.94435779750347\n",
      "   Epoch  71 | Sum of Loss: 173.7515737786889\n",
      "   Epoch  72 | Sum of Loss: 165.1644799374044\n",
      "   Epoch  73 | Sum of Loss: 161.3673210479319\n",
      "   Epoch  74 | Sum of Loss: 162.0584011375904\n",
      "   Epoch  75 | Sum of Loss: 164.42600962147117\n",
      "   Epoch  76 | Sum of Loss: 150.71723817288876\n",
      "   Epoch  77 | Sum of Loss: 157.7357708401978\n",
      "   Epoch  78 | Sum of Loss: 146.7594620026648\n",
      "   Epoch  79 | Sum of Loss: 146.40284819155931\n",
      "   Epoch  80 | Sum of Loss: 149.40700552240014\n",
      "   Epoch  81 | Sum of Loss: 142.8008322454989\n",
      "   Epoch  82 | Sum of Loss: 149.06396348029375\n",
      "   Epoch  83 | Sum of Loss: 140.7381955422461\n",
      "   Epoch  84 | Sum of Loss: 131.87872787564993\n",
      "   Epoch  85 | Sum of Loss: 133.92448659986258\n",
      "   Epoch  86 | Sum of Loss: 142.08729764074087\n",
      "   Epoch  87 | Sum of Loss: 133.6237698867917\n",
      "   Epoch  88 | Sum of Loss: 126.91733330115676\n",
      "   Epoch  89 | Sum of Loss: 133.97761237993836\n",
      "   Epoch  90 | Sum of Loss: 122.39942944049835\n",
      "   Epoch  91 | Sum of Loss: 118.32332937791944\n",
      "   Epoch  92 | Sum of Loss: 123.10647705197334\n",
      "   Epoch  93 | Sum of Loss: 128.5441993251443\n",
      "   Epoch  94 | Sum of Loss: 121.23177035152912\n",
      "   Epoch  95 | Sum of Loss: 119.91625378653407\n",
      "   Epoch  96 | Sum of Loss: 112.6903450153768\n",
      "   Epoch  97 | Sum of Loss: 115.74460925348103\n",
      "   Epoch  98 | Sum of Loss: 110.6950282342732\n",
      "   Epoch  99 | Sum of Loss: 106.07279669120908\n",
      "   Epoch 100 | Sum of Loss: 110.12299805879593\n",
      "Finish Training.\n",
      "Average Loss: 0.5549029457569122\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T05:25:35.390373Z",
     "start_time": "2024-09-11T05:22:03.920241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test(\n",
    "    num=2,\n",
    "    device=device,\n",
    "    n_epochs=100,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    ")"
   ],
   "id": "7f98f528e33d10bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<< 2 번째 테스트 >>>>>>>>>>>>>>>>>>>>\n",
      "device: mps\n",
      "batch_size: 128\n",
      "n_epochs: 100\n",
      "lr: 0.001\n",
      "num_workers: 4\n",
      "pin_memory: True\n",
      "--------------------------------------------------------------------------------\n",
      "   Epoch   1 | Sum of Loss: 3150.8514816761017\n",
      "   Epoch   2 | Sum of Loss: 1679.7778406143188\n",
      "   Epoch   3 | Sum of Loss: 1379.1406512260437\n",
      "   Epoch   4 | Sum of Loss: 1144.5657110214233\n",
      "   Epoch   5 | Sum of Loss: 965.2897183895111\n",
      "   Epoch   6 | Sum of Loss: 835.3759979009628\n",
      "   Epoch   7 | Sum of Loss: 740.6199172139168\n",
      "   Epoch   8 | Sum of Loss: 670.0202758312225\n",
      "   Epoch   9 | Sum of Loss: 614.7123789787292\n",
      "   Epoch  10 | Sum of Loss: 570.9902322292328\n",
      "   Epoch  11 | Sum of Loss: 535.584322988987\n",
      "   Epoch  12 | Sum of Loss: 505.4246777892113\n",
      "   Epoch  13 | Sum of Loss: 480.5290069580078\n",
      "   Epoch  14 | Sum of Loss: 459.2700951099396\n",
      "   Epoch  15 | Sum of Loss: 441.00994765758514\n",
      "   Epoch  16 | Sum of Loss: 423.262957662344\n",
      "   Epoch  17 | Sum of Loss: 408.32560378313065\n",
      "   Epoch  18 | Sum of Loss: 394.4544194638729\n",
      "   Epoch  19 | Sum of Loss: 382.3870116472244\n",
      "   Epoch  20 | Sum of Loss: 370.4121991097927\n",
      "   Epoch  21 | Sum of Loss: 359.48018804192543\n",
      "   Epoch  22 | Sum of Loss: 349.86567440629005\n",
      "   Epoch  23 | Sum of Loss: 340.8230318427086\n",
      "   Epoch  24 | Sum of Loss: 332.01553693413734\n",
      "   Epoch  25 | Sum of Loss: 323.90671795606613\n",
      "   Epoch  26 | Sum of Loss: 316.04313135147095\n",
      "   Epoch  27 | Sum of Loss: 308.97505927085876\n",
      "   Epoch  28 | Sum of Loss: 301.76662933826447\n",
      "   Epoch  29 | Sum of Loss: 294.8109876960516\n",
      "   Epoch  30 | Sum of Loss: 289.40147092938423\n",
      "   Epoch  31 | Sum of Loss: 283.04709047079086\n",
      "   Epoch  32 | Sum of Loss: 276.3923131376505\n",
      "   Epoch  33 | Sum of Loss: 271.900465965271\n",
      "   Epoch  34 | Sum of Loss: 265.7142862826586\n",
      "   Epoch  35 | Sum of Loss: 260.16165763139725\n",
      "   Epoch  36 | Sum of Loss: 255.06906239688396\n",
      "   Epoch  37 | Sum of Loss: 250.4165888428688\n",
      "   Epoch  38 | Sum of Loss: 246.22433285415173\n",
      "   Epoch  39 | Sum of Loss: 241.33546397089958\n",
      "   Epoch  40 | Sum of Loss: 238.01839488744736\n",
      "   Epoch  41 | Sum of Loss: 235.37838572263718\n",
      "   Epoch  42 | Sum of Loss: 230.10753133893013\n",
      "   Epoch  43 | Sum of Loss: 225.92719864845276\n",
      "   Epoch  44 | Sum of Loss: 224.3555293828249\n",
      "   Epoch  45 | Sum of Loss: 219.4494676142931\n",
      "   Epoch  46 | Sum of Loss: 217.1735582202673\n",
      "   Epoch  47 | Sum of Loss: 211.26351961493492\n",
      "   Epoch  48 | Sum of Loss: 210.46613308787346\n",
      "   Epoch  49 | Sum of Loss: 207.9436595737934\n",
      "   Epoch  50 | Sum of Loss: 203.01562786102295\n",
      "   Epoch  51 | Sum of Loss: 202.03250560164452\n",
      "   Epoch  52 | Sum of Loss: 198.4759711921215\n",
      "   Epoch  53 | Sum of Loss: 199.21220096945763\n",
      "   Epoch  54 | Sum of Loss: 192.16905908286572\n",
      "   Epoch  55 | Sum of Loss: 189.8780373632908\n",
      "   Epoch  56 | Sum of Loss: 188.42479035258293\n",
      "   Epoch  57 | Sum of Loss: 189.20703868567944\n",
      "   Epoch  58 | Sum of Loss: 182.82753284275532\n",
      "   Epoch  59 | Sum of Loss: 183.80275155603886\n",
      "   Epoch  60 | Sum of Loss: 179.15807914733887\n",
      "   Epoch  61 | Sum of Loss: 177.81862288713455\n",
      "   Epoch  62 | Sum of Loss: 178.15762934088707\n",
      "   Epoch  63 | Sum of Loss: 172.4981883764267\n",
      "   Epoch  64 | Sum of Loss: 173.75542703270912\n",
      "   Epoch  65 | Sum of Loss: 167.65464571118355\n",
      "   Epoch  66 | Sum of Loss: 167.70368434488773\n",
      "   Epoch  67 | Sum of Loss: 167.28538681566715\n",
      "   Epoch  68 | Sum of Loss: 163.46433736383915\n",
      "   Epoch  69 | Sum of Loss: 163.27984860539436\n",
      "   Epoch  70 | Sum of Loss: 159.0642481148243\n",
      "   Epoch  71 | Sum of Loss: 156.15260730683804\n",
      "   Epoch  72 | Sum of Loss: 163.4993760585785\n",
      "   Epoch  73 | Sum of Loss: 158.33137640357018\n",
      "   Epoch  74 | Sum of Loss: 150.86665204167366\n",
      "   Epoch  75 | Sum of Loss: 157.31673523783684\n",
      "   Epoch  76 | Sum of Loss: 156.62450140714645\n",
      "   Epoch  77 | Sum of Loss: 151.90634444355965\n",
      "   Epoch  78 | Sum of Loss: 152.53993400931358\n",
      "   Epoch  79 | Sum of Loss: 151.64690659940243\n",
      "   Epoch  80 | Sum of Loss: 142.42910517007113\n",
      "   Epoch  81 | Sum of Loss: 143.9914842620492\n",
      "   Epoch  82 | Sum of Loss: 147.91725599765778\n",
      "   Epoch  83 | Sum of Loss: 147.22707367688417\n",
      "   Epoch  84 | Sum of Loss: 136.16767927259207\n",
      "   Epoch  85 | Sum of Loss: 134.7388954013586\n",
      "   Epoch  86 | Sum of Loss: 139.76398684829473\n",
      "   Epoch  87 | Sum of Loss: 132.54233963042498\n",
      "   Epoch  88 | Sum of Loss: 131.93069776147604\n",
      "   Epoch  89 | Sum of Loss: 130.9438531473279\n",
      "   Epoch  90 | Sum of Loss: 134.32150694727898\n",
      "   Epoch  91 | Sum of Loss: 128.9391067624092\n",
      "   Epoch  92 | Sum of Loss: 128.07856038212776\n",
      "   Epoch  93 | Sum of Loss: 124.05670975148678\n",
      "   Epoch  94 | Sum of Loss: 127.15194807201624\n",
      "   Epoch  95 | Sum of Loss: 128.03615568578243\n",
      "   Epoch  96 | Sum of Loss: 128.55443446338177\n",
      "   Epoch  97 | Sum of Loss: 125.71573121100664\n",
      "   Epoch  98 | Sum of Loss: 120.69842055439949\n",
      "   Epoch  99 | Sum of Loss: 122.34549409151077\n",
      "   Epoch 100 | Sum of Loss: 116.5046635940671\n",
      "Finish Training.\n",
      "Average Loss: 0.5217055598974228\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T05:31:10.812703Z",
     "start_time": "2024-09-11T05:28:19.136686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test(\n",
    "    num=3,\n",
    "    device=device,\n",
    "    n_epochs=100,\n",
    "    lr=0.001,\n",
    "    batch_size=256,\n",
    ")"
   ],
   "id": "369f7ab6ae823b88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<< 3 번째 테스트 >>>>>>>>>>>>>>>>>>>>\n",
      "device: mps\n",
      "batch_size: 256\n",
      "n_epochs: 100\n",
      "lr: 0.001\n",
      "num_workers: 4\n",
      "pin_memory: True\n",
      "--------------------------------------------------------------------------------\n",
      "   Epoch   1 | Sum of Loss: 2076.8065502643585\n",
      "   Epoch   2 | Sum of Loss: 1012.5580270290375\n",
      "   Epoch   3 | Sum of Loss: 881.9028687477112\n",
      "   Epoch   4 | Sum of Loss: 793.462349653244\n",
      "   Epoch   5 | Sum of Loss: 719.9371078014374\n",
      "   Epoch   6 | Sum of Loss: 655.372013092041\n",
      "   Epoch   7 | Sum of Loss: 598.4144226312637\n",
      "   Epoch   8 | Sum of Loss: 548.2477571964264\n",
      "   Epoch   9 | Sum of Loss: 504.94272780418396\n",
      "   Epoch  10 | Sum of Loss: 467.46191585063934\n",
      "   Epoch  11 | Sum of Loss: 436.0094689130783\n",
      "   Epoch  12 | Sum of Loss: 409.0290081501007\n",
      "   Epoch  13 | Sum of Loss: 385.3111048936844\n",
      "   Epoch  14 | Sum of Loss: 364.8206013441086\n",
      "   Epoch  15 | Sum of Loss: 347.1907663345337\n",
      "   Epoch  16 | Sum of Loss: 331.1636708378792\n",
      "   Epoch  17 | Sum of Loss: 317.0799863934517\n",
      "   Epoch  18 | Sum of Loss: 304.8126300573349\n",
      "   Epoch  19 | Sum of Loss: 293.68153381347656\n",
      "   Epoch  20 | Sum of Loss: 283.97285717725754\n",
      "   Epoch  21 | Sum of Loss: 274.76148545742035\n",
      "   Epoch  22 | Sum of Loss: 266.37948274612427\n",
      "   Epoch  23 | Sum of Loss: 258.8849587440491\n",
      "   Epoch  24 | Sum of Loss: 251.6747498512268\n",
      "   Epoch  25 | Sum of Loss: 245.08607643842697\n",
      "   Epoch  26 | Sum of Loss: 239.08874440193176\n",
      "   Epoch  27 | Sum of Loss: 233.83836770057678\n",
      "   Epoch  28 | Sum of Loss: 228.69610178470612\n",
      "   Epoch  29 | Sum of Loss: 223.55972707271576\n",
      "   Epoch  30 | Sum of Loss: 219.0434936285019\n",
      "   Epoch  31 | Sum of Loss: 214.75011545419693\n",
      "   Epoch  32 | Sum of Loss: 210.51435405015945\n",
      "   Epoch  33 | Sum of Loss: 206.87282139062881\n",
      "   Epoch  34 | Sum of Loss: 202.76493936777115\n",
      "   Epoch  35 | Sum of Loss: 199.50422632694244\n",
      "   Epoch  36 | Sum of Loss: 196.0937525331974\n",
      "   Epoch  37 | Sum of Loss: 192.4899742603302\n",
      "   Epoch  38 | Sum of Loss: 189.69737911224365\n",
      "   Epoch  39 | Sum of Loss: 186.86282700300217\n",
      "   Epoch  40 | Sum of Loss: 183.81852668523788\n",
      "   Epoch  41 | Sum of Loss: 180.95922222733498\n",
      "   Epoch  42 | Sum of Loss: 178.50148475170135\n",
      "   Epoch  43 | Sum of Loss: 175.69404196739197\n",
      "   Epoch  44 | Sum of Loss: 173.12748703360558\n",
      "   Epoch  45 | Sum of Loss: 170.8500019609928\n",
      "   Epoch  46 | Sum of Loss: 168.08902782201767\n",
      "   Epoch  47 | Sum of Loss: 166.01978912949562\n",
      "   Epoch  48 | Sum of Loss: 164.2090538740158\n",
      "   Epoch  49 | Sum of Loss: 162.06313666701317\n",
      "   Epoch  50 | Sum of Loss: 160.5162869989872\n",
      "   Epoch  51 | Sum of Loss: 157.80193755030632\n",
      "   Epoch  52 | Sum of Loss: 156.18981862068176\n",
      "   Epoch  53 | Sum of Loss: 153.56406167149544\n",
      "   Epoch  54 | Sum of Loss: 151.92145603895187\n",
      "   Epoch  55 | Sum of Loss: 150.0820102095604\n",
      "   Epoch  56 | Sum of Loss: 148.50860100984573\n",
      "   Epoch  57 | Sum of Loss: 147.34843721985817\n",
      "   Epoch  58 | Sum of Loss: 145.58506870269775\n",
      "   Epoch  59 | Sum of Loss: 143.8156011402607\n",
      "   Epoch  60 | Sum of Loss: 142.14092525839806\n",
      "   Epoch  61 | Sum of Loss: 140.6486030817032\n",
      "   Epoch  62 | Sum of Loss: 138.5847989320755\n",
      "   Epoch  63 | Sum of Loss: 137.33347234129906\n",
      "   Epoch  64 | Sum of Loss: 135.90814954042435\n",
      "   Epoch  65 | Sum of Loss: 134.20032462477684\n",
      "   Epoch  66 | Sum of Loss: 133.4595911204815\n",
      "   Epoch  67 | Sum of Loss: 131.33520686626434\n",
      "   Epoch  68 | Sum of Loss: 130.3528493642807\n",
      "   Epoch  69 | Sum of Loss: 128.93981817364693\n",
      "   Epoch  70 | Sum of Loss: 127.5207833647728\n",
      "   Epoch  71 | Sum of Loss: 126.46909913420677\n",
      "   Epoch  72 | Sum of Loss: 125.01008078455925\n",
      "   Epoch  73 | Sum of Loss: 123.769651055336\n",
      "   Epoch  74 | Sum of Loss: 122.61185196042061\n",
      "   Epoch  75 | Sum of Loss: 121.82534325122833\n",
      "   Epoch  76 | Sum of Loss: 121.14802542328835\n",
      "   Epoch  77 | Sum of Loss: 120.22690817713737\n",
      "   Epoch  78 | Sum of Loss: 119.2785836160183\n",
      "   Epoch  79 | Sum of Loss: 116.70456394553185\n",
      "   Epoch  80 | Sum of Loss: 116.56016993522644\n",
      "   Epoch  81 | Sum of Loss: 115.714490711689\n",
      "   Epoch  82 | Sum of Loss: 114.70403665304184\n",
      "   Epoch  83 | Sum of Loss: 113.81098940968513\n",
      "   Epoch  84 | Sum of Loss: 112.76754233241081\n",
      "   Epoch  85 | Sum of Loss: 112.15983495116234\n",
      "   Epoch  86 | Sum of Loss: 110.55430191755295\n",
      "   Epoch  87 | Sum of Loss: 109.29253236949444\n",
      "   Epoch  88 | Sum of Loss: 107.64818984270096\n",
      "   Epoch  89 | Sum of Loss: 107.8329302072525\n",
      "   Epoch  90 | Sum of Loss: 106.43023198843002\n",
      "   Epoch  91 | Sum of Loss: 105.9517970085144\n",
      "   Epoch  92 | Sum of Loss: 105.70432463288307\n",
      "   Epoch  93 | Sum of Loss: 103.46356371045113\n",
      "   Epoch  94 | Sum of Loss: 103.52688506245613\n",
      "   Epoch  95 | Sum of Loss: 103.20357120037079\n",
      "   Epoch  96 | Sum of Loss: 104.41676743328571\n",
      "   Epoch  97 | Sum of Loss: 101.70760625600815\n",
      "   Epoch  98 | Sum of Loss: 102.23171128332615\n",
      "   Epoch  99 | Sum of Loss: 100.95857188105583\n",
      "   Epoch 100 | Sum of Loss: 100.4713657349348\n",
      "Finish Training.\n",
      "Average Loss: 0.6319701823711396\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T05:40:13.409013Z",
     "start_time": "2024-09-11T05:35:27.367307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test(\n",
    "    num=4,\n",
    "    device=device,\n",
    "    n_epochs=100,\n",
    "    lr=0.01,\n",
    "    batch_size=64,\n",
    ")"
   ],
   "id": "fa0b33abfa6cd4e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<< 4 번째 테스트 >>>>>>>>>>>>>>>>>>>>\n",
      "device: mps\n",
      "batch_size: 64\n",
      "n_epochs: 100\n",
      "lr: 0.01\n",
      "num_workers: 4\n",
      "pin_memory: True\n",
      "--------------------------------------------------------------------------------\n",
      "   Epoch   1 | Sum of Loss: 2085.6829941272736\n",
      "   Epoch   2 | Sum of Loss: 864.7714472711086\n",
      "   Epoch   3 | Sum of Loss: 649.5532964020967\n",
      "   Epoch   4 | Sum of Loss: 528.716418273747\n",
      "   Epoch   5 | Sum of Loss: 445.16699853539467\n",
      "   Epoch   6 | Sum of Loss: 381.3316645473242\n",
      "   Epoch   7 | Sum of Loss: 332.2157292589545\n",
      "   Epoch   8 | Sum of Loss: 285.7224821895361\n",
      "   Epoch   9 | Sum of Loss: 256.30247639864683\n",
      "   Epoch  10 | Sum of Loss: 223.39756705611944\n",
      "   Epoch  11 | Sum of Loss: 197.61556823179126\n",
      "   Epoch  12 | Sum of Loss: 177.30622961744666\n",
      "   Epoch  13 | Sum of Loss: 157.12740667909384\n",
      "   Epoch  14 | Sum of Loss: 142.71166347712278\n",
      "   Epoch  15 | Sum of Loss: 127.06254420801997\n",
      "   Epoch  16 | Sum of Loss: 115.15930036082864\n",
      "   Epoch  17 | Sum of Loss: 105.28968207538128\n",
      "   Epoch  18 | Sum of Loss: 94.83066885173321\n",
      "   Epoch  19 | Sum of Loss: 85.31770090572536\n",
      "   Epoch  20 | Sum of Loss: 77.73626125790179\n",
      "   Epoch  21 | Sum of Loss: 73.98513708636165\n",
      "   Epoch  22 | Sum of Loss: 65.31257713213563\n",
      "   Epoch  23 | Sum of Loss: 59.500364190898836\n",
      "   Epoch  24 | Sum of Loss: 55.1188155207783\n",
      "   Epoch  25 | Sum of Loss: 51.894426201470196\n",
      "   Epoch  26 | Sum of Loss: 47.352338928729296\n",
      "   Epoch  27 | Sum of Loss: 43.610002340748906\n",
      "   Epoch  28 | Sum of Loss: 41.499166168272495\n",
      "   Epoch  29 | Sum of Loss: 39.25108396727592\n",
      "   Epoch  30 | Sum of Loss: 36.6873024944216\n",
      "   Epoch  31 | Sum of Loss: 33.49869544617832\n",
      "   Epoch  32 | Sum of Loss: 31.424350482411683\n",
      "   Epoch  33 | Sum of Loss: 29.874017308466136\n",
      "   Epoch  34 | Sum of Loss: 29.318892302457243\n",
      "   Epoch  35 | Sum of Loss: 26.528525567613542\n",
      "   Epoch  36 | Sum of Loss: 24.562969432212412\n",
      "   Epoch  37 | Sum of Loss: 23.88210126524791\n",
      "   Epoch  38 | Sum of Loss: 23.491475638002157\n",
      "   Epoch  39 | Sum of Loss: 21.85676883906126\n",
      "   Epoch  40 | Sum of Loss: 20.84949811687693\n",
      "   Epoch  41 | Sum of Loss: 19.17648038221523\n",
      "   Epoch  42 | Sum of Loss: 17.96987690264359\n",
      "   Epoch  43 | Sum of Loss: 17.694085056893528\n",
      "   Epoch  44 | Sum of Loss: 16.464292000047863\n",
      "   Epoch  45 | Sum of Loss: 16.527937468141317\n",
      "   Epoch  46 | Sum of Loss: 15.595046133268625\n",
      "   Epoch  47 | Sum of Loss: 14.856543771922588\n",
      "   Epoch  48 | Sum of Loss: 14.074220686685294\n",
      "   Epoch  49 | Sum of Loss: 14.133797551970929\n",
      "   Epoch  50 | Sum of Loss: 13.737136112060398\n",
      "   Epoch  51 | Sum of Loss: 12.60440660174936\n",
      "   Epoch  52 | Sum of Loss: 12.861295357812196\n",
      "   Epoch  53 | Sum of Loss: 11.95976317115128\n",
      "   Epoch  54 | Sum of Loss: 11.720470630796626\n",
      "   Epoch  55 | Sum of Loss: 11.57312501501292\n",
      "   Epoch  56 | Sum of Loss: 10.855301136383787\n",
      "   Epoch  57 | Sum of Loss: 10.288294561440125\n",
      "   Epoch  58 | Sum of Loss: 10.855301657458767\n",
      "   Epoch  59 | Sum of Loss: 10.171016184613109\n",
      "   Epoch  60 | Sum of Loss: 9.99274875735864\n",
      "   Epoch  61 | Sum of Loss: 9.350650284439325\n",
      "   Epoch  62 | Sum of Loss: 9.295667422702536\n",
      "   Epoch  63 | Sum of Loss: 9.121113783447072\n",
      "   Epoch  64 | Sum of Loss: 8.77882241923362\n",
      "   Epoch  65 | Sum of Loss: 8.456675444729626\n",
      "   Epoch  66 | Sum of Loss: 8.119797349441797\n",
      "   Epoch  67 | Sum of Loss: 7.849756330018863\n",
      "   Epoch  68 | Sum of Loss: 8.008712298003957\n",
      "   Epoch  69 | Sum of Loss: 7.557429576525465\n",
      "   Epoch  70 | Sum of Loss: 7.282163884723559\n",
      "   Epoch  71 | Sum of Loss: 7.3323136596009135\n",
      "   Epoch  72 | Sum of Loss: 7.185231231851503\n",
      "   Epoch  73 | Sum of Loss: 7.090751494048163\n",
      "   Epoch  74 | Sum of Loss: 6.822311820695177\n",
      "   Epoch  75 | Sum of Loss: 6.498201719135977\n",
      "   Epoch  76 | Sum of Loss: 6.471299560973421\n",
      "   Epoch  77 | Sum of Loss: 6.445754195214249\n",
      "   Epoch  78 | Sum of Loss: 6.321955613442697\n",
      "   Epoch  79 | Sum of Loss: 6.725129112484865\n",
      "   Epoch  80 | Sum of Loss: 5.958256546407938\n",
      "   Epoch  81 | Sum of Loss: 6.032025510095991\n",
      "   Epoch  82 | Sum of Loss: 6.17393553594593\n",
      "   Epoch  83 | Sum of Loss: 5.787754264194518\n",
      "   Epoch  84 | Sum of Loss: 5.514280229690485\n",
      "   Epoch  85 | Sum of Loss: 5.39584599644877\n",
      "   Epoch  86 | Sum of Loss: 5.552976181148551\n",
      "   Epoch  87 | Sum of Loss: 5.758630537078716\n",
      "   Epoch  88 | Sum of Loss: 5.05794469313696\n",
      "   Epoch  89 | Sum of Loss: 5.876289544859901\n",
      "   Epoch  90 | Sum of Loss: 5.156881163828075\n",
      "   Epoch  91 | Sum of Loss: 4.6795787938172\n",
      "   Epoch  92 | Sum of Loss: 5.142063508625142\n",
      "   Epoch  93 | Sum of Loss: 4.886141686467454\n",
      "   Epoch  94 | Sum of Loss: 4.687047595740296\n",
      "   Epoch  95 | Sum of Loss: 4.968291034339927\n",
      "   Epoch  96 | Sum of Loss: 4.696591497864574\n",
      "   Epoch  97 | Sum of Loss: 4.557592898607254\n",
      "   Epoch  98 | Sum of Loss: 4.522097560344264\n",
      "   Epoch  99 | Sum of Loss: 4.53127991349902\n",
      "   Epoch 100 | Sum of Loss: 4.4186231810599566\n",
      "Finish Training.\n",
      "Average Loss: 0.39048321457505225\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T05:44:14.906541Z",
     "start_time": "2024-09-11T05:40:43.153398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test(\n",
    "    num=5,\n",
    "    device=device,\n",
    "    n_epochs=100,\n",
    "    lr=0.01,\n",
    "    batch_size=128,\n",
    ")"
   ],
   "id": "2fcd9ec0beedd9fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<< 5 번째 테스트 >>>>>>>>>>>>>>>>>>>>\n",
      "device: mps\n",
      "batch_size: 128\n",
      "n_epochs: 100\n",
      "lr: 0.01\n",
      "num_workers: 4\n",
      "pin_memory: True\n",
      "--------------------------------------------------------------------------------\n",
      "   Epoch   1 | Sum of Loss: 1382.9782609939575\n",
      "   Epoch   2 | Sum of Loss: 616.0506313443184\n",
      "   Epoch   3 | Sum of Loss: 447.3467983007431\n",
      "   Epoch   4 | Sum of Loss: 370.7292150557041\n",
      "   Epoch   5 | Sum of Loss: 314.6265758574009\n",
      "   Epoch   6 | Sum of Loss: 278.6782314777374\n",
      "   Epoch   7 | Sum of Loss: 249.84544822573662\n",
      "   Epoch   8 | Sum of Loss: 231.7423243522644\n",
      "   Epoch   9 | Sum of Loss: 204.89162692427635\n",
      "   Epoch  10 | Sum of Loss: 191.89213261008263\n",
      "   Epoch  11 | Sum of Loss: 173.74577514827251\n",
      "   Epoch  12 | Sum of Loss: 163.15161250531673\n",
      "   Epoch  13 | Sum of Loss: 153.6233011484146\n",
      "   Epoch  14 | Sum of Loss: 141.1562547981739\n",
      "   Epoch  15 | Sum of Loss: 130.07516093552113\n",
      "   Epoch  16 | Sum of Loss: 119.10069768875837\n",
      "   Epoch  17 | Sum of Loss: 115.08972583711147\n",
      "   Epoch  18 | Sum of Loss: 105.94933423399925\n",
      "   Epoch  19 | Sum of Loss: 99.4598857909441\n",
      "   Epoch  20 | Sum of Loss: 96.04597868025303\n",
      "   Epoch  21 | Sum of Loss: 91.87817554920912\n",
      "   Epoch  22 | Sum of Loss: 82.99731002748013\n",
      "   Epoch  23 | Sum of Loss: 81.35474164783955\n",
      "   Epoch  24 | Sum of Loss: 76.11682588979602\n",
      "   Epoch  25 | Sum of Loss: 69.40889389812946\n",
      "   Epoch  26 | Sum of Loss: 64.71969436481595\n",
      "   Epoch  27 | Sum of Loss: 63.13445429503918\n",
      "   Epoch  28 | Sum of Loss: 57.116881519556046\n",
      "   Epoch  29 | Sum of Loss: 58.305878791958094\n",
      "   Epoch  30 | Sum of Loss: 53.602916199713945\n",
      "   Epoch  31 | Sum of Loss: 52.44433696568012\n",
      "   Epoch  32 | Sum of Loss: 48.22836937755346\n",
      "   Epoch  33 | Sum of Loss: 46.87659541144967\n",
      "   Epoch  34 | Sum of Loss: 45.26614810526371\n",
      "   Epoch  35 | Sum of Loss: 48.34793400764465\n",
      "   Epoch  36 | Sum of Loss: 41.54075038060546\n",
      "   Epoch  37 | Sum of Loss: 37.43414791673422\n",
      "   Epoch  38 | Sum of Loss: 35.55440189316869\n",
      "   Epoch  39 | Sum of Loss: 33.76380973868072\n",
      "   Epoch  40 | Sum of Loss: 37.28180098719895\n",
      "   Epoch  41 | Sum of Loss: 34.22812480479479\n",
      "   Epoch  42 | Sum of Loss: 31.83570948243141\n",
      "   Epoch  43 | Sum of Loss: 30.558315308764577\n",
      "   Epoch  44 | Sum of Loss: 28.000942511484027\n",
      "   Epoch  45 | Sum of Loss: 30.078089034184813\n",
      "   Epoch  46 | Sum of Loss: 26.57105626538396\n",
      "   Epoch  47 | Sum of Loss: 26.432536084204912\n",
      "   Epoch  48 | Sum of Loss: 24.91752234660089\n",
      "   Epoch  49 | Sum of Loss: 25.979124853387475\n",
      "   Epoch  50 | Sum of Loss: 23.21019920706749\n",
      "   Epoch  51 | Sum of Loss: 23.727235585451126\n",
      "   Epoch  52 | Sum of Loss: 21.893259212374687\n",
      "   Epoch  53 | Sum of Loss: 20.083626613020897\n",
      "   Epoch  54 | Sum of Loss: 20.371149498969316\n",
      "   Epoch  55 | Sum of Loss: 19.30740133486688\n",
      "   Epoch  56 | Sum of Loss: 19.77440321817994\n",
      "   Epoch  57 | Sum of Loss: 18.47466165944934\n",
      "   Epoch  58 | Sum of Loss: 18.854412616230547\n",
      "   Epoch  59 | Sum of Loss: 17.120727686211467\n",
      "   Epoch  60 | Sum of Loss: 16.42495436221361\n",
      "   Epoch  61 | Sum of Loss: 15.695846906863153\n",
      "   Epoch  62 | Sum of Loss: 16.970336608588696\n",
      "   Epoch  63 | Sum of Loss: 15.660711001604795\n",
      "   Epoch  64 | Sum of Loss: 15.277828146703541\n",
      "   Epoch  65 | Sum of Loss: 16.547785135917366\n",
      "   Epoch  66 | Sum of Loss: 15.07833633478731\n",
      "   Epoch  67 | Sum of Loss: 13.993080357089639\n",
      "   Epoch  68 | Sum of Loss: 14.14192461129278\n",
      "   Epoch  69 | Sum of Loss: 11.880217977799475\n",
      "   Epoch  70 | Sum of Loss: 13.56633704341948\n",
      "   Epoch  71 | Sum of Loss: 13.441602210514247\n",
      "   Epoch  72 | Sum of Loss: 12.838041328825057\n",
      "   Epoch  73 | Sum of Loss: 13.668785486370325\n",
      "   Epoch  74 | Sum of Loss: 12.270230062305927\n",
      "   Epoch  75 | Sum of Loss: 11.203137715347111\n",
      "   Epoch  76 | Sum of Loss: 10.830643528141081\n",
      "   Epoch  77 | Sum of Loss: 11.621749757789075\n",
      "   Epoch  78 | Sum of Loss: 10.39656111318618\n",
      "   Epoch  79 | Sum of Loss: 10.12019660603255\n",
      "   Epoch  80 | Sum of Loss: 10.03970273770392\n",
      "   Epoch  81 | Sum of Loss: 9.354304360225797\n",
      "   Epoch  82 | Sum of Loss: 10.175554938148707\n",
      "   Epoch  83 | Sum of Loss: 11.160552035085857\n",
      "   Epoch  84 | Sum of Loss: 8.23755311127752\n",
      "   Epoch  85 | Sum of Loss: 9.982610052451491\n",
      "   Epoch  86 | Sum of Loss: 8.416052519809455\n",
      "   Epoch  87 | Sum of Loss: 10.06496623530984\n",
      "   Epoch  88 | Sum of Loss: 7.938996850978583\n",
      "   Epoch  89 | Sum of Loss: 10.397525261621922\n",
      "   Epoch  90 | Sum of Loss: 7.121374043636024\n",
      "   Epoch  91 | Sum of Loss: 8.190788673236966\n",
      "   Epoch  92 | Sum of Loss: 8.314191449433565\n",
      "   Epoch  93 | Sum of Loss: 8.049146464560181\n",
      "   Epoch  94 | Sum of Loss: 7.331102850381285\n",
      "   Epoch  95 | Sum of Loss: 8.606360159348696\n",
      "   Epoch  96 | Sum of Loss: 7.035732705611736\n",
      "   Epoch  97 | Sum of Loss: 8.198674893938005\n",
      "   Epoch  98 | Sum of Loss: 5.906670710071921\n",
      "   Epoch  99 | Sum of Loss: 6.929213228169829\n",
      "   Epoch 100 | Sum of Loss: 6.93424377636984\n",
      "Finish Training.\n",
      "Average Loss: 0.39707983317375184\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T05:47:21.568223Z",
     "start_time": "2024-09-11T05:44:27.260097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test(\n",
    "    num=6,\n",
    "    device=device,\n",
    "    n_epochs=100,\n",
    "    lr=0.01,\n",
    "    batch_size=256,\n",
    ")"
   ],
   "id": "1400b4dcd3646b9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<< 6 번째 테스트 >>>>>>>>>>>>>>>>>>>>\n",
      "device: mps\n",
      "batch_size: 256\n",
      "n_epochs: 100\n",
      "lr: 0.01\n",
      "num_workers: 4\n",
      "pin_memory: True\n",
      "--------------------------------------------------------------------------------\n",
      "   Epoch   1 | Sum of Loss: 904.2223970890045\n",
      "   Epoch   2 | Sum of Loss: 457.9501736164093\n",
      "   Epoch   3 | Sum of Loss: 336.07708871364594\n",
      "   Epoch   4 | Sum of Loss: 270.41756999492645\n",
      "   Epoch   5 | Sum of Loss: 227.63025611639023\n",
      "   Epoch   6 | Sum of Loss: 206.59857857227325\n",
      "   Epoch   7 | Sum of Loss: 188.93117955327034\n",
      "   Epoch   8 | Sum of Loss: 166.9390529692173\n",
      "   Epoch   9 | Sum of Loss: 149.57255464792252\n",
      "   Epoch  10 | Sum of Loss: 148.959058791399\n",
      "   Epoch  11 | Sum of Loss: 136.8480058312416\n",
      "   Epoch  12 | Sum of Loss: 128.68334129452705\n",
      "   Epoch  13 | Sum of Loss: 121.15905177593231\n",
      "   Epoch  14 | Sum of Loss: 115.82982394099236\n",
      "   Epoch  15 | Sum of Loss: 111.69681245088577\n",
      "   Epoch  16 | Sum of Loss: 102.5598232448101\n",
      "   Epoch  17 | Sum of Loss: 98.31871059536934\n",
      "   Epoch  18 | Sum of Loss: 91.8578664958477\n",
      "   Epoch  19 | Sum of Loss: 91.92310655117035\n",
      "   Epoch  20 | Sum of Loss: 84.05347643792629\n",
      "   Epoch  21 | Sum of Loss: 83.14143788814545\n",
      "   Epoch  22 | Sum of Loss: 80.79229012131691\n",
      "   Epoch  23 | Sum of Loss: 76.66300639510155\n",
      "   Epoch  24 | Sum of Loss: 68.89932353794575\n",
      "   Epoch  25 | Sum of Loss: 72.13433061540127\n",
      "   Epoch  26 | Sum of Loss: 64.93952591717243\n",
      "   Epoch  27 | Sum of Loss: 68.91344581544399\n",
      "   Epoch  28 | Sum of Loss: 61.73832067102194\n",
      "   Epoch  29 | Sum of Loss: 60.76758863776922\n",
      "   Epoch  30 | Sum of Loss: 56.04907312244177\n",
      "   Epoch  31 | Sum of Loss: 55.829728439450264\n",
      "   Epoch  32 | Sum of Loss: 53.167558804154396\n",
      "   Epoch  33 | Sum of Loss: 51.90039327740669\n",
      "   Epoch  34 | Sum of Loss: 50.28713262826204\n",
      "   Epoch  35 | Sum of Loss: 50.289290837943554\n",
      "   Epoch  36 | Sum of Loss: 48.01628066599369\n",
      "   Epoch  37 | Sum of Loss: 44.74571969360113\n",
      "   Epoch  38 | Sum of Loss: 44.34375945478678\n",
      "   Epoch  39 | Sum of Loss: 41.756417132914066\n",
      "   Epoch  40 | Sum of Loss: 42.12665926665068\n",
      "   Epoch  41 | Sum of Loss: 39.96488359570503\n",
      "   Epoch  42 | Sum of Loss: 37.40189925581217\n",
      "   Epoch  43 | Sum of Loss: 37.80499132722616\n",
      "   Epoch  44 | Sum of Loss: 38.06154130399227\n",
      "   Epoch  45 | Sum of Loss: 34.43257135152817\n",
      "   Epoch  46 | Sum of Loss: 36.18661890178919\n",
      "   Epoch  47 | Sum of Loss: 31.54062009602785\n",
      "   Epoch  48 | Sum of Loss: 32.87818545848131\n",
      "   Epoch  49 | Sum of Loss: 31.60748828202486\n",
      "   Epoch  50 | Sum of Loss: 31.863787539303303\n",
      "   Epoch  51 | Sum of Loss: 29.05457901954651\n",
      "   Epoch  52 | Sum of Loss: 29.660159450024366\n",
      "   Epoch  53 | Sum of Loss: 27.98413747921586\n",
      "   Epoch  54 | Sum of Loss: 27.320296477526426\n",
      "   Epoch  55 | Sum of Loss: 28.030764017254114\n",
      "   Epoch  56 | Sum of Loss: 23.9823674634099\n",
      "   Epoch  57 | Sum of Loss: 26.530454225838184\n",
      "   Epoch  58 | Sum of Loss: 25.876396138221025\n",
      "   Epoch  59 | Sum of Loss: 25.36276527494192\n",
      "   Epoch  60 | Sum of Loss: 23.254744853824377\n",
      "   Epoch  61 | Sum of Loss: 22.784764144569635\n",
      "   Epoch  62 | Sum of Loss: 22.217296961694956\n",
      "   Epoch  63 | Sum of Loss: 22.52782339975238\n",
      "   Epoch  64 | Sum of Loss: 23.31418565660715\n",
      "   Epoch  65 | Sum of Loss: 19.852706786245108\n",
      "   Epoch  66 | Sum of Loss: 20.177775513380766\n",
      "   Epoch  67 | Sum of Loss: 20.313453752547503\n",
      "   Epoch  68 | Sum of Loss: 21.301826637238264\n",
      "   Epoch  69 | Sum of Loss: 21.297748861834407\n",
      "   Epoch  70 | Sum of Loss: 18.435892023146152\n",
      "   Epoch  71 | Sum of Loss: 16.455773949623108\n",
      "   Epoch  72 | Sum of Loss: 19.103602312505245\n",
      "   Epoch  73 | Sum of Loss: 17.66040713340044\n",
      "   Epoch  74 | Sum of Loss: 18.139099398627877\n",
      "   Epoch  75 | Sum of Loss: 16.356350837275386\n",
      "   Epoch  76 | Sum of Loss: 17.401672046631575\n",
      "   Epoch  77 | Sum of Loss: 16.778680393472314\n",
      "   Epoch  78 | Sum of Loss: 16.69489286467433\n",
      "   Epoch  79 | Sum of Loss: 16.138592643663287\n",
      "   Epoch  80 | Sum of Loss: 15.588694294914603\n",
      "   Epoch  81 | Sum of Loss: 14.542019251734018\n",
      "   Epoch  82 | Sum of Loss: 15.44890128262341\n",
      "   Epoch  83 | Sum of Loss: 13.817951949313283\n",
      "   Epoch  84 | Sum of Loss: 12.450286291539669\n",
      "   Epoch  85 | Sum of Loss: 15.69826590269804\n",
      "   Epoch  86 | Sum of Loss: 13.880474703386426\n",
      "   Epoch  87 | Sum of Loss: 16.85087695531547\n",
      "   Epoch  88 | Sum of Loss: 13.459430800750852\n",
      "   Epoch  89 | Sum of Loss: 13.27086777985096\n",
      "   Epoch  90 | Sum of Loss: 12.711121425032616\n",
      "   Epoch  91 | Sum of Loss: 13.000732563436031\n",
      "   Epoch  92 | Sum of Loss: 12.846468279138207\n",
      "   Epoch  93 | Sum of Loss: 10.462069850414991\n",
      "   Epoch  94 | Sum of Loss: 11.788383295759559\n",
      "   Epoch  95 | Sum of Loss: 12.020512208342552\n",
      "   Epoch  96 | Sum of Loss: 10.975115796551108\n",
      "   Epoch  97 | Sum of Loss: 12.146037364378572\n",
      "   Epoch  98 | Sum of Loss: 12.1461013071239\n",
      "   Epoch  99 | Sum of Loss: 10.884510856121778\n",
      "   Epoch 100 | Sum of Loss: 9.351305224001408\n",
      "Finish Training.\n",
      "Average Loss: 0.41579486504793167\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f078bedf48c81ff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
