{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LLM 으로 뉴스기사 분류해보기",
   "id": "e2143cdf0e9369d0"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-15T10:09:52.632772Z",
     "start_time": "2024-10-15T10:09:52.257878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "hugging_face_token = os.getenv(\"HUGGING_FACE_TOKEN\")\n",
    "\n",
    "login(hugging_face_token)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/joyuiyeong/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## GEMMA 모델과 Tokenizer 로드하기",
   "id": "de53b1d639cfc27e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T10:09:57.654331Z",
     "start_time": "2024-10-15T10:09:52.641581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\", device_map=\"auto\")\n",
    "print(model.device)\n",
    "model"
   ],
   "id": "e354b1a4c5123ead",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b41f3913a93416f9944d9d0a9c3668d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GemmaForCausalLM(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-17): 18 x GemmaDecoderLayer(\n",
       "        (self_attn): GemmaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): GemmaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T10:09:57.772918Z",
     "start_time": "2024-10-15T10:09:57.770254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def clear_cache():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    elif torch.backends.mps.is_available():\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "\n",
    "my_device = get_device()\n",
    "my_device"
   ],
   "id": "e8897f01ba9ce770",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Zero-Shot 분류 함수 정의",
   "id": "82ae729ccbd0e38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T10:09:57.790371Z",
     "start_time": "2024-10-15T10:09:57.787506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize(device, text):\n",
    "    tokenized_text = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    return tokenized_text[\"input_ids\"], tokenized_text[\"attention_mask\"]\n",
    "\n",
    "\n",
    "def zero_shot_classification(device, task_description, text, candidate_labels):\n",
    "    question_input_ids, question_attention_mask = tokenize(\n",
    "        device, task_description + text\n",
    "    )\n",
    "    scores = []\n",
    "    for label in candidate_labels:\n",
    "        label_input_ids, label_attention_mask = tokenize(device, label)\n",
    "        num_label_tokens = label_input_ids.shape[-1] - 1\n",
    "\n",
    "        input_ids = torch.concatenate(\n",
    "            [question_input_ids, label_input_ids[..., 1:]], axis=-1\n",
    "        )\n",
    "        attention_mask = torch.concatenate(\n",
    "            [question_attention_mask, label_attention_mask[..., 1:]], axis=-1\n",
    "        )\n",
    "\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "        num_total_token = input_ids.shape[-1]\n",
    "        score = sum(\n",
    "            [\n",
    "                logits[0, num_total_token - i, label_input_ids[0, i].item()]\n",
    "                for i in range(num_label_tokens, 0, -1)\n",
    "            ]\n",
    "        )\n",
    "        scores.append(score)\n",
    "\n",
    "        del input_ids\n",
    "        del attention_mask\n",
    "        del logits\n",
    "\n",
    "        clear_cache()\n",
    "    return scores"
   ],
   "id": "e2459f16650441e4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## AG News 데이터셋 로드하기\n",
    "- 4개의 뉴스 카테고리\n",
    "    - 1: World, 2: Sports, 3: Business, 4: Science/Technology"
   ],
   "id": "5ee09dab82a64062"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T10:10:03.485204Z",
     "start_time": "2024-10-15T10:09:57.803548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds_ag_news = load_dataset(\"fancyzhx/ag_news\")\n",
    "ds_ag_news"
   ],
   "id": "449533689be4e506",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T10:10:03.729108Z",
     "start_time": "2024-10-15T10:10:03.502799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_function(data):\n",
    "    return tokenizer(data[\"text\"])\n",
    "\n",
    "\n",
    "tokenized_ds = ds_ag_news.map(preprocess_function, batched=True)"
   ],
   "id": "ddb9fb95e407f69c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## test 데이터셋으로 분류해보기",
   "id": "f696cb244b78d5ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T10:10:34.602687Z",
     "start_time": "2024-10-15T10:10:03.741732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "NUM_TEST = 50\n",
    "total_correctness = 0\n",
    "task_description = \"A short news article is given. Decide which category the article belongs to. Article: \"\n",
    "candidate_labels = [\n",
    "    \"Answer: World\",\n",
    "    \"Answer: Sports\",\n",
    "    \"Answer: Business\",\n",
    "    \"Answer: Science/Technology\",\n",
    "]\n",
    "\n",
    "for i in tqdm(range(NUM_TEST)):\n",
    "    text = tokenized_ds[\"test\"][i][\"text\"]\n",
    "    label = tokenized_ds[\"test\"][i][\"label\"]\n",
    "\n",
    "    scores = zero_shot_classification(\n",
    "        device=my_device,\n",
    "        task_description=task_description,\n",
    "        text=text,\n",
    "        candidate_labels=candidate_labels,\n",
    "    )\n",
    "\n",
    "    prediction = torch.argmax(torch.Tensor(scores)).item()\n",
    "    if prediction == label:\n",
    "        total_correctness += 1"
   ],
   "id": "6c6545bb16f4819d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:30<00:00,  1.62it/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T10:10:34.693189Z",
     "start_time": "2024-10-15T10:10:34.691444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Total Correctness: \", total_correctness)\n",
    "print(\"Accuracy: \", total_correctness / NUM_TEST)"
   ],
   "id": "fae47bfa9447373f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correctness:  9\n",
      "Accuracy:  0.18\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T10:10:34.795071Z",
     "start_time": "2024-10-15T10:10:34.720708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "clear_cache()"
   ],
   "id": "d27d4e1951d8274",
   "outputs": [],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
