{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T05:32:23.295344Z",
     "start_time": "2024-10-15T05:32:23.287802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "hugging_face_token = os.getenv(\"HUGGING_FACE_TOKEN\")"
   ],
   "id": "a9e177f5d4fb8f35",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-15T05:32:37.588335Z",
     "start_time": "2024-10-15T05:32:37.229598Z"
    }
   },
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(hugging_face_token)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/joyuiyeong/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T05:32:46.658875Z",
     "start_time": "2024-10-15T05:32:39.381090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\", device_map=\"auto\")"
   ],
   "id": "c0551aac3016d3fc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4430ad8f965a446fad6f10f8b0faa2f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:20:31.612770Z",
     "start_time": "2024-10-15T08:20:31.609435Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.special_tokens_map",
   "id": "f14b4932b878d986",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<bos>',\n",
       " 'eos_token': '<eos>',\n",
       " 'unk_token': '<unk>',\n",
       " 'pad_token': '<pad>',\n",
       " 'additional_special_tokens': ['<start_of_turn>', '<end_of_turn>']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T05:32:56.538240Z",
     "start_time": "2024-10-15T05:32:54.578655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "my_device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "input_text = \"What is your name?\"\n",
    "\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(my_device)\n",
    "\n",
    "outputs = model.generate(**input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ],
   "id": "782bfeb0d273b465",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joyuiyeong/.pyenv/versions/deeplearning/lib/python3.11/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>What is your name?\n",
      "\n",
      "What is your age?\n",
      "\n",
      "What is your gender?\n",
      "\n",
      "What\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T05:35:33.764974Z",
     "start_time": "2024-10-15T05:35:33.302957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokens = input_ids[\"input_ids\"]\n",
    "print(tokens)\n",
    "\n",
    "logits = model(**input_ids).logits\n",
    "for i in range(tokens.shape[-1]):\n",
    "    token = tokens[0, i].item()\n",
    "    print(logits[0, i, token])"
   ],
   "id": "ab0dc95541931684",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     2,   1841,    603,    861,   1503, 235336]], device='mps:0')\n",
      "tensor(-18.2746, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor(-33.2665, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor(-23.9536, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor(-27.7627, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor(-19.6064, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor(-21.0372, device='mps:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Zero-shot classification 구현해보기\n",
    "\n",
    "### Zero-shot learning\n",
    "- 정의: 모델이 이전에 본 적 없는 클래스나 작업을 수행하는 능력입니다.\n",
    "- 특징: 훈련 데이터에 없던 새로운 카테고리의 데이터를 처리할 수 있습니다.\n",
    "- 작동 원리: 기존 지식을 바탕으로 새로운 상황에 일반화하여 적용합니다.\n",
    "- 예시: 개와 고양이를 구분하도록 훈련된 모델이 사자 이미지를 보고 '고양이과' 동물로 분류하는 경우\n",
    "\n",
    "### Few-shot learning\n",
    "- 정의: 매우 적은 수의 예시만으로 새로운 작업을 수행하는 능력입니다.\n",
    "- 특징: 소수의 학습 예제만으로 새로운 개념을 빠르게 습득합니다.\n",
    "- 작동 원리: 주어진 소수의 예시를 바탕으로 패턴을 파악하고 일반화합니다.\n",
    "- 예시: 5개의 한국어 문장과 영어 번역을 보고, 새로운 한국어 문장을 영어로 번역하는 경우"
   ],
   "id": "ea5fc1ed9f769de3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:21:31.955290Z",
     "start_time": "2024-10-15T08:21:31.952408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def zero_shot_classification(device, text, task_description, labels):\n",
    "    tokenized_question = tokenizer(task_description + text, return_tensors=\"pt\").to(\n",
    "        device\n",
    "    )\n",
    "    question_input_ids = tokenized_question[\"input_ids\"]\n",
    "    question_attention_mask = tokenized_question[\"attention_mask\"]\n",
    "\n",
    "    probs = []\n",
    "    for label in labels:\n",
    "        tokenized_label = tokenizer(label, return_tensors=\"pt\").to(device)\n",
    "        label_input_ids = tokenized_label[\"input_ids\"]\n",
    "        label_attention_mask = tokenized_label[\"attention_mask\"]\n",
    "        num_label_tokens = (\n",
    "            label_input_ids.shape[-1] - 1\n",
    "        )  # 문장 나누는 special token 을 뺀 것\n",
    "\n",
    "        concatenated_input_ids = torch.concatenate(\n",
    "            [question_input_ids, label_input_ids[:, 1:]], axis=-1\n",
    "        )\n",
    "        concatenated_attention_mask = torch.concatenate(\n",
    "            [question_attention_mask, label_attention_mask[:, 1:]], axis=-1\n",
    "        )\n",
    "\n",
    "        logits = model(\n",
    "            input_ids=concatenated_input_ids, attention_mask=concatenated_attention_mask\n",
    "        ).logits\n",
    "        prob = 0\n",
    "        num_total_token = concatenated_input_ids.shape[-1]\n",
    "        for i in range(num_label_tokens, 0, -1):\n",
    "            token = label_input_ids[0, i].item()\n",
    "            prob += logits[0, num_total_token - i, token].item()\n",
    "        probs.append(prob)\n",
    "\n",
    "        torch.mps.empty_cache()\n",
    "    return probs"
   ],
   "id": "594f5ce999ce08",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:21:17.057001Z",
     "start_time": "2024-10-15T08:21:16.238271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "probs = zero_shot_classification(\n",
    "    my_device,\n",
    "    \"I am happy!\",\n",
    "    \"Is the sentence positive or negative?: \",\n",
    "    [\"positive\", \"negative\"],\n",
    ")\n",
    "print(probs)"
   ],
   "id": "a057fa0f76dd24b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10.642311096191406, -11.575439453125]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 영화 리뷰에 대해서 Zero-Shot 해보기",
   "id": "876a88f334c640af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:25:51.369183Z",
     "start_time": "2024-10-15T08:25:35.391227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb = load_dataset(\"imdb\")\n",
    "\n",
    "\n",
    "def preprocess_function(data):\n",
    "    return tokenizer(data[\"text\"], truncation=True, padding=\"max_length\")\n",
    "\n",
    "\n",
    "tokenized_imdb = imdb.map(preprocess_function, batched=True)"
   ],
   "id": "4e76056b70658cac",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e67677ce9a244e88c261183c535168c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5caa0446d134d8299dddb0249a2661f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac46c8136c5a4c27a96892c778842f33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:30:06.679243Z",
     "start_time": "2024-10-15T08:29:32.364398Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:34<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 28,
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_correct = 0\n",
    "for i in tqdm(range(50)):\n",
    "    text = tokenized_imdb[\"test\"][i][\"text\"]\n",
    "    label = tokenized_imdb[\"test\"][i][\"label\"]\n",
    "    probs = zero_shot_classification(\n",
    "        device=my_device,\n",
    "        text=text,\n",
    "        task_description=\"A movie review is given. Decide that the movie review is positive or negative: \",\n",
    "        labels=[\"Answer: negative.\", \"Answer: positive.\"],\n",
    "    )\n",
    "    pred = np.argmax(np.array(probs))\n",
    "    if pred == label:\n",
    "        n_correct += 1"
   ],
   "id": "8daf24c714816a65"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:30:38.571412Z",
     "start_time": "2024-10-15T08:30:38.568838Z"
    }
   },
   "cell_type": "code",
   "source": "print(n_correct, n_correct / 50)",
   "id": "6d1655e3b3b9d863",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 0.86\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
